{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulation libraries\n",
    "import numpy as np    #Install numpy\n",
    "import pandas as pd   #Install pandas\n",
    "import networkx as nx #Install networkx\n",
    "import random\n",
    "import statsmodels.stats.power as smp #Install statsmodels\n",
    "import math\n",
    "\n",
    "#Plotting Libraries\n",
    "import matplotlib.pyplot as plt #Install matplotlib\n",
    "import time\n",
    "from scipy import stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Simulation of one generation\n",
    "def competition(lifeSpan, sampleSize, startupCost, sampleCost, ExpDistributionShape, scoopedCost, negativeResultCost, limit, randomWalkP,acceptP): \n",
    "    oneYear = lifeSpan/10 #Duration of one timePeriod in the model\n",
    "    scientistID = list(np.arange(populationSize))  #ID to keep track of scientists\n",
    "    amountOfQuestions = round((lifeSpan / (startupCost + minSampleSize)) * populationSize + populationSize) #Generates pool of questions\n",
    "    questionID = list(np.arange(amountOfQuestions)) #ID to keep track of questions\n",
    "    effectSizeQuestion = list(np.round(np.array(np.random.exponential(1/ExpDistributionShape, size=amountOfQuestions)), 1)) #Pool of effect sizes Determined by lambda\n",
    "    drawerQ = list(np.array(np.zeros(shape=[populationSize, 0]),np.int32)) #File drawer of papers\n",
    "    drawerR = list(np.array(np.zeros(shape=[populationSize, 0]),np.bool_)) #File drawer of results linked to papers\n",
    "\n",
    "    #Initialize variables\n",
    "    workedOnQuestions = 0  #To calculate questions worked on\n",
    "    publishedQuestions = 0 #To calculate questions published\n",
    "    totalAuthors = 0 #To calculate authors per paper\n",
    "    PNMatrix = np.array([[0,0,0,0],[0,0,0,0]]) #To store confusion matrix\n",
    "    drawerPN = list(np.array(np.zeros(shape=[populationSize, 0]),np.int32)) #To store all results, even if removed from file-drawer\n",
    "\n",
    "    #Dataframe consisting of the scientist population\n",
    "    d1 = {'scientistID' : scientistID, 'sampleSize' : sampleSize, 'questionID' : 0, 'publications' : 0, 'payoff' : 0.0, 'RandomWalkP': randomWalkP , 'AcceptP': acceptP }\n",
    "    scientistDataFrame = pd.DataFrame(data=d1)\n",
    "    \n",
    "    #Dataframe for storing all the results\n",
    "    d2 = {'questionID' : questionID, 'scientistID' : -1, 'sampleSize' : 0, 'effectSize': effectSizeQuestion,'result' : 0, 'published': None, 'coWriters':\"None\"}\n",
    "    resultsDataFrame = pd.DataFrame(data=d2)\n",
    "    resultsDataFrame['coWriters'].astype('object') #store object types\n",
    "\n",
    "    #Generate a co-authorship network\n",
    "    averageNeighbours = 8 \n",
    "    rewiringP = 0.1\n",
    "    scientistNetwork = nx.watts_strogatz_graph(populationSize, averageNeighbours, rewiringP)\n",
    "    for i in ([e for e in scientistNetwork.edges]): #Add edge weights based on neighbours in common\n",
    "        scientistNetwork[i[0]][i[1]]['weight'] = len( sorted(  nx.common_neighbors(scientistNetwork, i[0], i[1])  ) ) + 1\n",
    "\n",
    "    #For the PCI credit system contribution shares have to be stored for each paper worked on\n",
    "    if payoffMechanism == \"PCI\":\n",
    "        PCIcontributions = [None]*amountOfQuestions\n",
    "    \n",
    "    #Tracking which questions are published and worked on\n",
    "    questionIDsPublished = [] \n",
    "    questionIDsWorked = [] \n",
    "    \n",
    "    #Initialize time in the model\n",
    "    timePeriod = 1 #starting time period\n",
    "    timeCostBaseline = list(scientistDataFrame['sampleSize'] * sampleCost + startupCost)  #Base cost for a scientists study, start-up cost + sample size\n",
    "    timeCost = [[],[]]                          #Used to keep track of what kind of event takes place and when, because there are two types of events\n",
    "    timeCost[0] = timeCostBaseline              #Curent event time\n",
    "    timeCost[1] = np.zeros(populationSize)      #Track whether the current event is a co-write event(0) or lead-author event(1), \n",
    "                                                # for the lead-author results have to be calculated while when a collaboration has been finished\n",
    "                                                # no results have to be calculated\n",
    "    timeCostBacklog = np.zeros(populationSize)  #Store commitments made to work on collaborations, which have to be completed after current event\n",
    "    timeCostRealTime = timeCostBaseline         #Track the backlog and current event times combined\n",
    "\n",
    "    yearProgress = oneYear-1 # time to next year tracker\n",
    "    unpubQ = questionID # list of all questions that havent been worked on\n",
    "    \n",
    "    #Running the simulation in a loop, until the lifeSpan has been reached\n",
    "    while(timePeriod < lifeSpan):\n",
    "        timeToNextEvent = min(yearProgress, min( min(timeCost[0]), lifeSpan - timePeriod)) #Check which event is first to take place\n",
    "        if limit: #used to toggle limit on or off\n",
    "            yearProgress = yearProgress - timeToNextEvent \n",
    "        timeCost[0] = list(timeCost[0] - np.repeat(timeToNextEvent, len(timeCost[0]))) #Forward time for scientists on current event\n",
    "        timePeriod = timePeriod + timeToNextEvent  #Forward time period\n",
    "        timeCostRealTime = list(timeCostRealTime - np.repeat(timeToNextEvent, len(timeCost[0]))) #Forward total time for scientists\n",
    "        if (timePeriod > lifeSpan):\n",
    "            break\n",
    "\n",
    "        if (min(timeCost[0]) == 0.0): # studies are completed -> scientists store questions into their drawer\n",
    "            if limit == False: #used to toggle limit on or off\n",
    "                yearProgress = 0\n",
    "            actingScientists = list(np.array([i for i, noTimeLeft in enumerate(timeCost[0]) if noTimeLeft == 0])) #Scientist who have an event\n",
    "            newQuestionSearchers = list(actingScientists) #Scientists who need a new question, so have no backlog that has to be completed\n",
    "\n",
    "            \n",
    "            removeActingScientists = []\n",
    "            removeQuestionSearchers = []\n",
    "            for sid in actingScientists: #Check what has to happen for each scientist that has an event\n",
    "                if timeCost[1][sid] == 0:\n",
    "                    removeActingScientists.append(sid) # We need not to calculate results, this was a co-write event\n",
    "                    if timeCostBacklog[sid] != 0:      # We need not to move them on to a new question, they have a backlog to be completed\n",
    "                        removeQuestionSearchers.append(sid)\n",
    "                        timeCost[0][sid] = timeCostBacklog[sid] \n",
    "                        timeCost[1][sid] = 0\n",
    "                        timeCostBacklog[sid] = 0\n",
    "                if (timeCost[1][sid] == 1) and (timeCostBacklog[sid] != 0): #We need to calculate results, but they have to complete a backlog\n",
    "                    removeQuestionSearchers.append(sid)\n",
    "                    timeCost[0][sid] = timeCostBacklog[sid]\n",
    "                    timeCost[1][sid] = 0\n",
    "                    timeCostBacklog[sid] = 0\n",
    "            actingScientists = [x for x in actingScientists if x not in removeActingScientists] #These are all scientists who need a new RQ\n",
    "            newQuestionSearchers = [x for x in newQuestionSearchers if x not in removeQuestionSearchers] #These are all scientists we need to calculate results for\n",
    "\n",
    "\n",
    "            #Calculate results for the scientists who finished their study\n",
    "            if len(actingScientists) != 0: \n",
    "                amountActingScientists = len(actingScientists) \n",
    "                questionActingScientists = list(scientistDataFrame[scientistDataFrame['scientistID'].isin(actingScientists)]['questionID']) #Retrieve the question\n",
    "                effectSizeQuestion = [] \n",
    "                for i in questionActingScientists: \n",
    "                    effectSizeQuestion.append(resultsDataFrame.loc[[i],'effectSize']) #Retrieve the effect size\n",
    "                sampleSizeActingScientists = list(scientistDataFrame[scientistDataFrame['scientistID'].isin(actingScientists)]['sampleSize']) #Retrieve the Sample Size\n",
    "                sampleSizeIndex = 0 \n",
    "\n",
    "                powerOfQuestions = [] \n",
    "                for qid in questionActingScientists: #Calculate the power they have on a given effect size\n",
    "                        resultsDataFrame.at[qid,'published'] = False \n",
    "                        powerOfQuestion =  smp.ttest_power( effect_size= resultsDataFrame._get_value(qid, 'effectSize'),nobs=sampleSizeActingScientists[sampleSizeIndex], \n",
    "                                                        alpha=0.05, alternative='two-sided') \n",
    "                        powerOfQuestions.append(powerOfQuestion) \n",
    "                        sampleSizeIndex += 1 \n",
    "\n",
    "                positiveResult = [] \n",
    "                for r in range(amountActingScientists): #Calculate whether they get a positive result\n",
    "                    positiveResult.append(np.random.uniform(0,1) < powerOfQuestions[r]) \n",
    "\n",
    "                index = 0\n",
    "                for sid in actingScientists: #Store whether the result they got was a TP,FP,TN,FN\n",
    "                    qid = questionActingScientists[np.where(actingScientists == sid)[0][0]] \n",
    "                    workedOnQuestions += 1\n",
    "                    if (resultsDataFrame.at[qid, 'effectSize'] > 0) and (positiveResult[index] == True): # True Positive\n",
    "                        PNMatrix[0][0] += 1\n",
    "                        drawerPN[sid] = np.append(drawerPN[sid], 0) \n",
    "                    elif  (resultsDataFrame.at[qid, 'effectSize'] == 0) and (positiveResult[index] == True): # False Positive\n",
    "                        PNMatrix[0][1] += 1\n",
    "                        drawerPN[sid] = np.append(drawerPN[sid], 1) \n",
    "                    elif (resultsDataFrame.at[qid, 'effectSize'] == 0) and (positiveResult[index] == False): # True Negative\n",
    "                        PNMatrix[0][2] += 1\n",
    "                        drawerPN[sid] = np.append(drawerPN[sid], 2) \n",
    "                    elif (resultsDataFrame.at[qid, 'effectSize'] > 0) and (positiveResult[index] == False):# False Negative\n",
    "                        PNMatrix[0][3] += 1\n",
    "                        drawerPN[sid] = np.append(drawerPN[sid], 3) \n",
    "                    index += 1\n",
    "\n",
    "                for sid in actingScientists: #Add the completed questions and results to a scientists drawer\n",
    "                    qid = questionActingScientists[np.where(actingScientists == sid)[0][0]] \n",
    "                    drawerQ[sid] = np.append(drawerQ[sid], [qid]) \n",
    "                    drawerR[sid] = np.append(drawerR[sid], [positiveResult[np.where(actingScientists == sid)[0][0]]]) \n",
    "                questionIDsWorked = np.concatenate((questionIDsWorked, questionActingScientists)) #Update questions worked on\n",
    "            \n",
    "                for sid in actingScientists: #Update results dataFrame with the results\n",
    "                    qid = questionActingScientists[np.where(actingScientists == sid)[0][0]] \n",
    "                    resultsDataFrame.loc[[qid],'scientistID'] = sid \n",
    "                    resultsDataFrame.loc[[qid],'sampleSize'] = sampleSizeActingScientists[np.where(actingScientists == sid)[0][0]] \n",
    "                    resultsDataFrame.loc[[qid],'result'] = positiveResult[np.where(actingScientists == sid)[0][0]] \n",
    "            \n",
    "            #All scientists who need new questions, get new questions\n",
    "            if len(newQuestionSearchers) != 0:\n",
    "                for sid in newQuestionSearchers: \n",
    "                    nextQuestion = np.random.choice(unpubQ) #Randomly select an unpublished question\n",
    "                    scientistDataFrame.at[sid, 'questionID'] = nextQuestion #Update dataframe that scientist has new question\n",
    "\n",
    "                for lsid in newQuestionSearchers: #Use their collaboration strategy to find collaborators\n",
    "\n",
    "                    if scientistDataFrame.at[lsid, 'RandomWalkP'] > 0.01: #If they are willing to collaborate, they go on a random walk\n",
    "                        startNodeRWP = scientistDataFrame.at[lsid, 'RandomWalkP'] #Retrieve RWP strategy\n",
    "                        startNode = lsid   #Remember start node  \n",
    "                        currentNode = lsid #Start at own node\n",
    "                        endWalk = False    #Parameter to check whether random walk has ended\n",
    "                        path = [startNode] #Keep track of the path walked\n",
    "                        studyCost = timeCostBaseline[lsid] #Baseline cost of the scientist doing the walk\n",
    "\n",
    "\n",
    "                        while endWalk == False:\n",
    "                            randomNumber = np.random.uniform(0,1,1)\n",
    "                            if randomNumber < startNodeRWP: #Determine whether the scientists keeps walking\n",
    "                                neighbors = [n for n in scientistNetwork[currentNode]] #Get neighbouring nodes to the node currently at\n",
    "                                neighbors = [x for x in neighbors if x not in path] #Remove neighbours already visited from path\n",
    "                                if len(neighbors) != 0: #If there is a neighbour to move to\n",
    "                                    transitionWeights = list([])\n",
    "                                    for nsid in neighbors:\n",
    "                                        transitionWeights.append(scientistNetwork[currentNode][nsid]['weight']) #Get all edge weights\n",
    "                                    choice = random.choices(neighbors, weights = transitionWeights , k = 1) #Make a choice which direction to go\n",
    "                                    currentNode = choice[0] #This is the new node the scientist end up at\n",
    "                                    path.append(currentNode) #Add this node to the path\n",
    "                                    if len(path) > 40: #End walk if the path lengh is longer than 40\n",
    "                                        endWalk = True\n",
    "                                        path.remove(startNode)\n",
    "                                        candidates = path\n",
    "                                else: #If no neighbours the path ends as well\n",
    "                                    endWalk = True\n",
    "                                    path.remove(startNode)\n",
    "                                    candidates = path\n",
    "                            else: #The decision to stop walking was made\n",
    "                                endWalk = True\n",
    "                                path.remove(startNode)\n",
    "                                candidates = path\n",
    "                        candidates = [x for x in candidates if ((timeCostRealTime[x]) < (studyCost) )] #These are all collaboration candidates\n",
    "\n",
    "                        candidatesAccepted = [] \n",
    "                        candidatesBacklog = []\n",
    "\n",
    "                        if len(candidates) != 0: #If any candidates are in the path\n",
    "                            for csid in candidates:\n",
    "                                if scientistDataFrame.at[csid, 'AcceptP'] > np.random.uniform(0,1,1) :#Check whether the candidates accept the collaboration\n",
    "                                    candidatesAccepted.append(csid) #ID of accepted scientists\n",
    "                                    candidatesBacklog.append(timeCostRealTime[csid]) #Current task length to be completed of candidates\n",
    "\n",
    "                        if len(candidatesAccepted) != 0: #If somebody accepted the request\n",
    "\n",
    "                            weights = [1*precisionWeights] #Set precision of contribution shares generated\n",
    "                            numberOfCandidates = len(candidatesAccepted) \n",
    "                            piecesContribution = np.zeros((numberOfCandidates, numberOfCandidates+1)) #To store contribution shares\n",
    "\n",
    "                            for i in range(numberOfCandidates): #Generate possible contribution shares up to the number of candidates\n",
    "                                                                # e.g. if 3 candidates than shares for 1,2 and 3 candidates are generated to see which one fits\n",
    "                                if i < 4: #Contribution share weight based on position\n",
    "                                    weights.append((1/(i+2))* precisionWeights)\n",
    "                                else: #limit minimum contribution share weight to 1/5 \n",
    "                                    weights.append((1/(5))* precisionWeights)\n",
    "\n",
    "                                #Store these contribution shares for each number of candidates in a matrix\n",
    "                                contributions = np.round(np.random.dirichlet((weights), 1),2) \n",
    "                                emptySpace = np.array(  [np.repeat(0,   ( numberOfCandidates - (i+1) ))] )\n",
    "                                contributions = (np.concatenate((contributions, emptySpace), axis=1)).reshape(numberOfCandidates + 1)\n",
    "                                piecesContribution[i] = contributions\n",
    "                            piecesCost = piecesContribution * studyCost #multiply shares with timecost of study to be conducted\n",
    "\n",
    "                            #Order scientists by the time they have available\n",
    "                            possibleShares = []\n",
    "                            orderedList = [list(e) for e in zip(candidatesAccepted, candidatesBacklog)] \n",
    "                            orderedList.sort(key = lambda orderedList: orderedList[1])\n",
    "                            candidatesBacklog = list(np.array(orderedList)[:,1])\n",
    "                            candidatesAccepted = list(np.array(orderedList)[:,0])\n",
    "\n",
    "                            #See which candidates can work on the contributions\n",
    "                            for i in range(numberOfCandidates):\n",
    "                                if all(  np.array(candidatesBacklog[:i+1] + piecesCost[i][1:i+2]) <= np.array(piecesCost[i][0])  ):\n",
    "                                    possibleShares.append(i)\n",
    "\n",
    "                            #If no candidates can work on the paper, the lead-author continues as a single author\n",
    "                            if len(possibleShares) == 0: #no co-writing can occur\n",
    "                                timeCost[0][lsid] = timeCostBaseline[lsid] \n",
    "                                timeCostRealTime[lsid] = timeCostBaseline[lsid]\n",
    "                                timeCost[1][lsid] = 1\n",
    "                                totalAuthors += 1\n",
    "\n",
    "                            #There are candidates who can work on the contribution, they will become co-authors\n",
    "                            else: \n",
    "                                bestOption = max(possibleShares) #Highest amount of writers possible\n",
    "                                qid = scientistDataFrame.loc[scientistDataFrame['scientistID'] == lsid]['questionID'].item() #Get question they will work on\n",
    "                                selectedCandidates = candidatesAccepted[:len(piecesCost[bestOption][1:bestOption+2])] \n",
    "                                selectedCandidates = [int(a) for a in selectedCandidates] #These are all available candidates\n",
    "                                if payoffMechanism == \"PCI\": #Store contribution shares in case of the PCI payoff mechanism\n",
    "                                    PCIcontributions[qid] = piecesContribution[bestOption]\n",
    "                                resultsDataFrame.at[qid, \"coWriters\"] = selectedCandidates #Set these authors as co-writers on the given question\n",
    "\n",
    "                                pieceCount = 1\n",
    "                                for sid in selectedCandidates: #Add the time cost of the contribution share to co-writers timecost\n",
    "                                    timeCostBacklog[sid] += np.round(piecesCost[bestOption][pieceCount]) #Update backlog with timecost\n",
    "                                    timeCostRealTime[sid] += np.round(piecesCost[bestOption][pieceCount]) #Update total time cost to be completed\n",
    "                                    pieceCount += 1\n",
    "                                timeCost[0][lsid] = np.round(piecesCost[bestOption][0]) + len(selectedCandidates) * 10 #add timecost of lead-author\n",
    "                                timeCostRealTime[lsid] = np.round(piecesCost[bestOption][0]) + len(selectedCandidates) * 10 #add timecost of lead-author\n",
    "                                timeCost[1][lsid] = 1 \n",
    "                                totalAuthors += 1 + len(selectedCandidates)    \n",
    "\n",
    "                        if len(candidates) == 0 or len(candidatesAccepted)==0: #No co-writing can occur\n",
    "                            timeCost[0][lsid] = timeCostBaseline[lsid] \n",
    "                            timeCost[1][lsid] = 1  \n",
    "                            timeCostRealTime[lsid] = timeCostBaseline[lsid] \n",
    "                            totalAuthors += 1     \n",
    "\n",
    "                    else:  #This author has a RWP of 0, so they will work as a solo-author\n",
    "                        timeCost[0][lsid] = timeCostBaseline[lsid]\n",
    "                        timeCost[1][lsid] = 1\n",
    "                        timeCostRealTime[lsid] = timeCostBaseline[lsid]\n",
    "                        totalAuthors += 1\n",
    "\n",
    "        #A time period has ended, scientists can publish studies             \n",
    "        if yearProgress == 0: \n",
    "            yearProgress = oneYear #Reset timeperiod progress\n",
    "\n",
    "            for sid in np.repeat(scientistDataFrame['scientistID'], paperLimit): #Scientists can publish equal to the paper limit\n",
    "                workedQ = drawerQ[sid] #Retrieve worked on questions\n",
    "                if len(workedQ) != 0:#If the scientist has completed any questions\n",
    "                    payoff = 0  #Initialize payoff\n",
    "                    for q in workedQ: #Select the question with the highest payoff\n",
    "                        priorPublished = questionIDsPublished.count(q) \n",
    "                        noveltyResult = pow( (1/(1+priorPublished)), scoopedCost) #Calculate the decreased value, if a scientist got scooped\n",
    "                        indexQuestionR = list(workedQ).index(q)\n",
    "                        if drawerR[sid][indexQuestionR]: \n",
    "                            possiblepayoff = noveltyResult #Keep track of highest payoff question\n",
    "                            fullpayoff = possiblepayoff \n",
    "                        else: \n",
    "                            possiblepayoff = noveltyResult * negativeResultCost #Decrease value if negative result\n",
    "                            fullpayoff = possiblepayoff\n",
    "\n",
    "                        if resultsDataFrame.at[q, 'coWriters'] != \"None\": #Check if the question was co-written on\n",
    "                            amountCoWriters = len(resultsDataFrame.at[q, 'coWriters'])\n",
    "                            if payoffMechanism == \"EC\": #Decrease value because of multiple authors\n",
    "                                fullpayoff = possiblepayoff\n",
    "                                possiblepayoff = (1/(amountCoWriters + 1))* possiblepayoff\n",
    "                            elif payoffMechanism == \"PCI\": #Decrease value because of multiple authors\n",
    "                                fullpayoff = possiblepayoff\n",
    "                                possiblepayoff = PCIcontributions[q][0] * possiblepayoff\n",
    "                        if possiblepayoff > payoff: #Save question with highest payoff\n",
    "                            chosenQ = q \n",
    "                            payoff = fullpayoff\n",
    "\n",
    "                           \n",
    "                    payoff = np.round(payoff,2) #Round the payoff\n",
    "                    scientistDataFrame.at[sid, 'publications'] += 1 #Add publication to dataframe\n",
    "                    if resultsDataFrame.at[chosenQ, 'coWriters'] != \"None\": #Calculate payoff for potential co-writers\n",
    "                        coWriters = resultsDataFrame.at[chosenQ, 'coWriters']\n",
    "                        authors = [sid] + coWriters\n",
    "                        if payoffMechanism == \"Fixed\": #Fixed payoff for collaborators\n",
    "                            for csid in authors:\n",
    "                                scientistDataFrame.at[csid, 'payoff'] += payoff\n",
    "                        if payoffMechanism == \"SDC\": #SDC payoff for collaborators\n",
    "                            positionCount = 1\n",
    "                            for csid in authors:\n",
    "                                scientistDataFrame.at[csid, 'payoff'] += np.round( (1/positionCount) * payoff, 2) \n",
    "                                positionCount += 1\n",
    "                        if payoffMechanism == \"EC\": #EC payoff for collaborators\n",
    "                            for csid in authors:\n",
    "                                scientistDataFrame.at[csid, 'payoff'] += np.round( (1/len(authors) * payoff), 2)\n",
    "                        if payoffMechanism == \"PCI\": #PCI payoff for collaborators\n",
    "                            contributionsPayoff = PCIcontributions[chosenQ] #Retrieve contribution shares\n",
    "                            positionCount = 0\n",
    "                            for csid in authors:\n",
    "                                scientistDataFrame.at[csid, 'payoff'] += np.round( contributionsPayoff[positionCount] * payoff, 2)\n",
    "                                positionCount += 1           \n",
    "                    else: \n",
    "                        scientistDataFrame.at[sid, 'payoff'] += payoff #No collaborations, payoff for single author\n",
    "\n",
    "                    #Update all drawers and the dataframe that this question is published\n",
    "                    questionIDsPublished.append(chosenQ) \n",
    "                    resultsDataFrame.at[chosenQ, 'published'] = True                  \n",
    "                    publishedQuestions += 1\n",
    "                    if chosenQ in unpubQ:\n",
    "                        unpubQ.remove(chosenQ)\n",
    "                    indexQuestionQ = list(workedQ).index(chosenQ)\n",
    "                    PNMatrix[1][drawerPN[sid][indexQuestionQ]] += 1\n",
    "                    drawerPN[sid] = np.delete(drawerPN[sid], indexQuestionQ) \n",
    "                    drawerQ[sid] = np.delete(drawerQ[sid], indexQuestionQ) \n",
    "                    drawerR[sid] = np.delete(drawerR[sid], indexQuestionQ) \n",
    "\n",
    "\n",
    "    #Track descriptive statistics from this generation\n",
    "    averageAuthors = np.round( totalAuthors / workedOnQuestions , 2)\n",
    "    drawerSize = 0\n",
    "    for i in range(populationSize):\n",
    "        drawerSize += len(drawerQ[i])\n",
    "    averageDrawerSize = drawerSize / populationSize\n",
    "\n",
    "    #Return descriptive statistics to be saved\n",
    "    return scientistDataFrame, publishedQuestions, averageDrawerSize, averageAuthors, workedOnQuestions, PNMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let scientists in new generations adopt new strategies\n",
    "def evolution(lifeSpan, generations, startupCost, sampleCost, ExpDistributionShape, scoopedCost, negativeResultCost, limit):\n",
    "    # initialize population, with uniform sample sizes\n",
    "    sampleSize = np.round(np.random.uniform(minSampleSize, maxSampleSize, populationSize)) # draw sample sizes from a uniform distribution\n",
    "    #Possibility to toggle collaborations on and off\n",
    "    if collaborations == False:\n",
    "        randomWalkP = np.zeros(populationSize)\n",
    "        acceptP = np.zeros(populationSize)\n",
    "    else:\n",
    "        randomWalkP = np.round( ((np.random.uniform(0, 100, populationSize))/100),2)\n",
    "        acceptP = np.round( ((np.random.uniform(0, 100, populationSize))/100),2 )\n",
    "    #Descriptive statistics that are going to be tracked across generations\n",
    "    meanSampleSizes = []   \n",
    "    meanPayoffs = []       \n",
    "    meanPublished = []  \n",
    "    meanAP = []\n",
    "    meanRWP = []\n",
    "    averageAuthors = []   \n",
    "    questionsWorked = []            \n",
    "    drawerSizes = []\n",
    "    finalAP = []\n",
    "    finalRWP = []\n",
    "    finalSS = []\n",
    "    finalPN = []\n",
    "\n",
    "    #Print statement between model repeats\n",
    "    print( loopCount, \"/10. Working with: // Paper limit =\", str(limit), \"(\",str(paperLimit),\") // Collaborations =\", str(collaborations), \"(\", str(payoffMechanism), \") // Generations =\", generations)\n",
    "    print(\"  |\", end=\"\")\n",
    "\n",
    "    #For every generation we update the strategies\n",
    "    for g in range(generations): \n",
    "        print(g+1, end=\"|\")\n",
    "\n",
    "        #Retrieve information from completed generation\n",
    "        result = competition(lifeSpan, sampleSize, startupCost, sampleCost, ExpDistributionShape, scoopedCost, negativeResultCost, limit,                                      randomWalkP, acceptP) \n",
    "        outcomeGeneration = result[0]\n",
    "        publishedQuestions = result[1]\n",
    "        averageDrawerSizeGeneration = result[2]\n",
    "        averageAuthorsGeneration = result[3]\n",
    "        questionsWorkedOn = result[4]\n",
    "        PNMatrix = result[5]\n",
    "\n",
    "        #Select the strategies from scientists that were most succesfull based on payoff\n",
    "        evolutionID = outcomeGeneration.sample(n=populationSize, weights=outcomeGeneration[\"payoff\"], random_state=1, replace= True)['scientistID'].to_numpy()\n",
    "        sid = 0\n",
    "\n",
    "        #The new generation scientists will adopt these strategies with some noise\n",
    "        for evid in evolutionID:\n",
    "            sampleSize[sid] = np.absolute(np.round(np.random.normal(outcomeGeneration.at[evid, 'sampleSize'], 5, 1))) #Adopting sample size strategy\n",
    "            if collaborations == False:\n",
    "                randomWalkP[sid] = 0\n",
    "                acceptP[sid] = 0\n",
    "            else:          \n",
    "                randomWalkP[sid] = np.random.normal(outcomeGeneration.at[evid, \"RandomWalkP\"] ,0.02 ,1) #Adopting RWP strategy\n",
    "                acceptP[sid] = np.random.normal(outcomeGeneration.at[evid, \"AcceptP\"] ,0.05 ,1) #Adopting AP strategy\n",
    "            if randomWalkP[sid] > 0.95: #Limiting probabilities to 0.95 and making sure they are not negative\n",
    "                randomWalkP[sid] = 0.95\n",
    "            if randomWalkP[sid] < 0.00:\n",
    "                randomWalkP[sid] = 0.00\n",
    "            if acceptP[sid] > 0.95:\n",
    "                acceptP[sid] = 0.95\n",
    "            if acceptP[sid] < 0:\n",
    "                acceptP[sid] = 0\n",
    "            sid += 1\n",
    "\n",
    "        #Descriptive statistics from all generations are saved in these arrays\n",
    "        combinedPO.append(outcomeGeneration[\"payoff\"].mean())\n",
    "        combinedQW.append(questionsWorkedOn)\n",
    "        combinedSS.append(outcomeGeneration[\"sampleSize\"].mean())\n",
    "        combinedAP.append(outcomeGeneration[\"AcceptP\"].mean()*100)\n",
    "        combinedRWP.append(outcomeGeneration[\"RandomWalkP\"].mean()*100)\n",
    "        combinedAA.append(averageAuthorsGeneration)\n",
    "        combinedDRAW.append(averageDrawerSizeGeneration)\n",
    "        combinedPUB.append(publishedQuestions)\n",
    "        \n",
    "        #Save extra information about the convergence of the last generation\n",
    "        if (g == generations - 1): \n",
    "            if collaborations == True:\n",
    "                finalAP = outcomeGeneration[\"AcceptP\"].to_numpy() * 100\n",
    "                finalRWP = outcomeGeneration[\"RandomWalkP\"].to_numpy() * 100\n",
    "                finalSS = outcomeGeneration[\"sampleSize\"].to_numpy() \n",
    "                finalPN = PNMatrix\n",
    "            else:\n",
    "                finalAP = np.zeros(populationSize)\n",
    "                finalRWP = np.zeros(populationSize)\n",
    "                finalSS = outcomeGeneration[\"sampleSize\"].to_numpy()\n",
    "                finalPN = PNMatrix \n",
    "        \n",
    "        #Save confusion matrix for published and all questions\n",
    "        totalW = np.sum(PNMatrix[0])\n",
    "        totalP = np.sum(PNMatrix[1])\n",
    "        TP.append(PNMatrix[0][0]/totalW)\n",
    "        TPP.append(PNMatrix[1][0]/totalP)\n",
    "        FP.append(PNMatrix[0][1]/totalW)\n",
    "        FPP.append(PNMatrix[1][1]/totalP)\n",
    "        TN.append(PNMatrix[0][2]/totalW)\n",
    "        TNP.append(PNMatrix[1][2]/totalP)\n",
    "        FN.append(PNMatrix[0][3]/totalW)\n",
    "        FNP.append(PNMatrix[1][3]/totalP)\n",
    "\n",
    "    return finalAP, finalRWP, finalSS, finalPN\n",
    "    "
   ]
  },
  {
   "source": [
    "loopCount = 0\n",
    "\n",
    "#Initialize all arrays that are used to save descriptive statistics\n",
    "TP = []\n",
    "TPP = []\n",
    "FP = []\n",
    "FPP = []\n",
    "TN = []\n",
    "TNP = []\n",
    "FN = []\n",
    "FNP = []\n",
    "combinedPO = []\n",
    "combinedSS = []\n",
    "combinedAP = []\n",
    "combinedRWP = []\n",
    "combinedAA = []\n",
    "combinedDRAW = []\n",
    "combinedQW = []\n",
    "combinedPUB = []\n",
    "\n",
    "#####################################################################################\n",
    "############################ SET SIMULATION PARAMETERS ##############################\n",
    "#####################################################################################\n",
    "\n",
    "#### Simulation Length and Size ####\n",
    "repeats = 10          #Amount of repeats\n",
    "generationsT = 500    #Generations per repeat\n",
    "populationSize = 120  #Size of population in the model\n",
    "lifeSpanT = 10000     #Amount of time units population is alive for\n",
    "\n",
    "#### Costs and Effect Sizes #### \n",
    "minSampleSize = 2\n",
    "maxSampleSize = 1000  #Set initialization sample sizes\n",
    "ExpDistributionShapeT = 8 #Set lambda of exp. distribution\n",
    "startupCostT = 200    #Start up costs for study\n",
    "sampleCostT =  1      #Cost for every sample\n",
    "scoopedCostT = 0.5    #Cost of being scooped\n",
    "negativeResultCostT = 0.5 #Cost of finding a negative result\n",
    "\n",
    "#### Paper Limit ####\n",
    "limit = True    #Toggle Limit\n",
    "paperLimit = 1  #Height of the paper limit\n",
    "\n",
    "#### Collaborations ####\n",
    "collaborations = False   #Toggle collaborations\n",
    "payoffMechanism = \"SDC\"  #Select payoff mechanism\n",
    "precisionWeights = 100   #Set precision of contribution shares\n",
    "\n",
    "#####################################################################################\n",
    "\n",
    "#Let the model run for X amount of repeats\n",
    "for i in range (repeats):\n",
    "    print()\n",
    "    loopCount += 1\n",
    "    start = time.time()\n",
    "    plot = evolution (lifeSpanT, generationsT, startupCostT, sampleCostT, ExpDistributionShapeT, scoopedCostT, negativeResultCostT, limit)\n",
    "    end = time.time() #Display time used per repeat\n",
    "    print(\"Minutes:\", np.round((end - start)/60,2))\n",
    "\n",
    "# Saving all descriptive statistics in a .npz file, that can be opened with NumPy\n",
    "finalAP = plot[0]\n",
    "finalRWP = plot[1]\n",
    "finalSS = plot[2]\n",
    "finalPN = plot[3]     \n",
    "combinedPO = np.array(combinedPO).reshape(repeats, generationsT) \n",
    "combinedQW = np.array(combinedQW).reshape(repeats, generationsT)\n",
    "combinedSS = np.array(combinedSS).reshape(repeats, generationsT)\n",
    "combinedAP = np.array(combinedAP).reshape(repeats, generationsT)\n",
    "combinedRWP = np.array(combinedRWP).reshape(repeats, generationsT)\n",
    "combinedAA = np.array(combinedAA).reshape(repeats, generationsT)\n",
    "combinedDRAW = np.array(combinedDRAW).reshape(repeats, generationsT)\n",
    "combinedPUB = np.array(combinedPUB).reshape(repeats, generationsT)\n",
    "TP = np.array(TP).reshape(repeats, generationsT)\n",
    "TPP = np.array(TPP).reshape(repeats, generationsT)\n",
    "FP = np.array(FP).reshape(repeats, generationsT)\n",
    "FPP = np.array(FPP).reshape(repeats, generationsT)\n",
    "TN = np.array(TN).reshape(repeats, generationsT)\n",
    "TNP = np.array(TNP).reshape(repeats, generationsT)\n",
    "FN = np.array(FN).reshape(repeats, generationsT)\n",
    "FNP = np.array(FNP).reshape(repeats, generationsT)\n",
    "\n",
    "name = \"BaseOne\"\n",
    "np.savez( name + '.npz', \n",
    "finalAP = finalAP,\n",
    "finalRWP = finalRWP,\n",
    "finalSS = finalSS,\n",
    "finalPN = finalPN, \n",
    "combinedPO = combinedPO, \n",
    "combinedQW = combinedQW,\n",
    "combinedSS = combinedSS,\n",
    "combinedAP = combinedAP,\n",
    "combinedRWP = combinedRWP, \n",
    "combinedAA = combinedAA,\n",
    "combinedDRAW = combinedDRAW,\n",
    "combinedPUB = combinedPUB,\n",
    "TP = TP,\n",
    "TPP = TPP,\n",
    "FP = FP,\n",
    "FPP = FPP,\n",
    "TN = TN,\n",
    "TNP = TNP,\n",
    "FN = FN,\n",
    "FNP = FNP)\n"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "1 /10. Working with: // Paper limit = True ( 1 ) // Collaborations = False ( SDC ) // Generations = 500\n",
      "  |1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20|21|22|23|24|25|26|27|28|29|30|31|32|33|34|35|36|37|38|39|40|41|42|43|44|45|46|47|48|49|50|51|52|53|54|55|56|57|58|59|60|61|62|63|64|65|66|67|68|69|70|71|72|73|74|75|76|77|78|79|80|81|82|83|84|85|86|87|88|89|90|91|92|93|94|95|96|97|98|99|100|101|102|103|104|105|106|107|108|109|110|111|112|113|114|115|116|117|118|119|120|121|122|123|124|125|126|127|128|129|130|131|132|133|134|135|136|137|138|139|140|141|142|143|144|145|146|147|148|149|150|151|152|153|154|155|156|157|158|159|160|161|162|163|164|165|166|167|168|169|170|171|172|173|174|175|176|177|178|179|180|181|182|183|184|185|186|187|188|189|190|191|192|193|194|195|196|197|198|199|200|201|202|203|204|205|206|207|208|209|210|211|212|213|214|215|216|217|218|219|220|221|222|223|224|225|226|227|228|229|230|231|232|233|234|235|236|237|238|239|240|241|242|243|244|245|246|247|248|249|250|251|252|253|254|255|256|257|258|259|260|261|262|263|264|265|266|267|268|269|270|271|272|273|274|275|276|277|278|279|280|281|282|283|284|285|286|287|288|289|290|291|292|293|294|295|296|297|298|299|300|301|302|303|304|305|306|307|308|309|310|311|312|313|314|315|316|317|318|319|320|321|322|323|324|325|326|327|328|329|330|331|332|333|334|335|336|337|338|339|340|341|342|343|344|345|346|347|348|349|350|351|352|353|354|355|356|357|358|359|360|361|362|363|364|365|366|367|368|369|370|371|372|373|374|375|376|377|378|379|380|381|382|383|384|385|386|387|388|389|390|391|392|393|394|395|396|397|398|399|400|401|402|403|404|405|406|407|408|409|410|411|412|413|414|415|416|417|418|419|420|421|422|423|424|425|426|427|428|429|430|431|432|433|434|435|436|437|438|439|440|441|442|443|444|445|446|447|448|449|450|451|452|453|454|455|456|457|458|459|460|461|462|463|464|465|466|467|468|469|470|471|472|473|474|475|476|477|478|479|480|481|482|483|484|485|486|487|488|489|490|491|492|493|494|495|496|497|498|499|500|Minutes: 127.45\n",
      "\n",
      "2 /10. Working with: // Paper limit = True ( 1 ) // Collaborations = False ( SDC ) // Generations = 500\n",
      "  |1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20|21|22|23|24|25|26|27|28|29|30|31|32|33|34|35|36|37|38|39|40|41|42|43|44|45|46|47|48|49|50|51|52|53|54|55|56|57|58|59|60|61|62|63|64|65|66|67|68|69|70|71|72|73|74|75|76|77|78|79|80|81|82|83|84|85|86|87|88|89|90|91|92|93|94|95|96|97|98|99|100|101|102|103|104|105|106|107|108|109|110|111|112|113|114|115|116|117|118|119|120|121|122|123|124|125|126|127|128|129|130|131|132|133|134|135|136|137|138|139|140|141|142|143|144|145|146|147|148|149|150|151|152|153|154|155|156|157|158|159|160|161|162|163|164|165|166|167|168|169|170|171|172|173|174|175|176|177|178|179|180|181|182|183|184|185|186|187|188|189|190|191|192|193|194|195|196|197|198|199|200|201|202|203|204|205|206|207|208|209|210|211|212|213|214|215|216|217|218|219|220|221|222|223|224|225|226|227|228|229|230|231|232|233|234|235|236|237|238|239|240|241|242|243|244|245|246|247|248|249|250|251|252|253|254|255|256|257|258|259|260|261|262|263|264|265|266|267|268|269|270|271|272|273|274|275|276|277|278|279|280|281|282|283|284|285|286|287|288|289|290|291|292|293|294|295|296|297|298|299|300|301|302|303|304|305|306|307|308|309|310|311|312|313|314|315|316|317|318|319|320|321|322|323|324|325|326|327|328|329|330|331|332|333|334|335|336|337|338|339|340|341|342|343|344|345|346|347|348|349|350|351|352|353|354|355|356|357|358|359|360|361|362|363|364|365|366|367|368|369|370|371|372|373|374|375|376|377|378|379|380|381|382|383|384|385|386|387|388|389|390|391|392|393|394|395|396|397|398|399|400|401|402|403|404|405|406|407|408|409|410|411|412|413|414|415|416|417|418|419|420|421|422|423|424|425|426|427|428|429|430|431|432|433|434|435|436|437|438|439|440|441|442|443|444|445|446|447|448|449|450|451|452|453|454|455|456|457|458|459|460|461|462|463|464|465|466|467|468|469|470|471|472|473|474|475|476|477|478|479|480|481|482|483|484|485|486|487|488|489|490|491|492|493|494|495|496|497|498|499|500|Minutes: 151.78\n",
      "\n",
      "3 /10. Working with: // Paper limit = True ( 1 ) // Collaborations = False ( SDC ) // Generations = 500\n",
      "  |1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20|21|22|23|24|25|26|27|28|29|30|31|32|33|34|35|36|37|38|39|40|41|42|43|44|45|46|47|48|49|50|51|52|53|54|55|56|57|58|59|60|61|62|63|64|65|66|67|68|69|70|71|72|73|74|75|76|77|78|79|80|81|82|83|84|85|86|87|88|89|90|91|92|93|94|95|96|97|98|99|100|101|102|103|104|105|106|107|108|109|110|111|112|113|114|115|116|117|118|119|120|121|122|123|124|125|126|127|128|129|130|131|132|133|134|135|136|137|138|139|140|141|142|143|144|145|146|147|148|149|150|151|152|153|154|155|156|157|158|159|160|161|162|163|164|165|166|167|168|169|170|171|172|173|174|175|176|177|178|179|180|181|182|183|184|185|186|187|188|189|190|191|192|193|194|195|196|197|198|199|200|201|202|203|204|205|206|207|208|209|210|211|212|213|214|215|216|217|218|219|220|221|222|223|224|225|226|227|228|229|230|231|232|233|234|235|236|237|238|239|240|241|242|243|244|245|246|247|248|249|250|251|252|253|254|255|256|257|258|259|260|261|262|263|264|265|266|267|268|269|270|271|272|273|274|275|276|277|278|279|280|281|282|283|284|285|286|287|288|289|290|291|292|293|294|295|296|297|298|299|300|301|302|303|304|305|306|307|308|309|310|311|312|313|314|315|316|317|318|319|320|321|322|323|324|325|326|327|328|329|330|331|332|333|334|335|336|337|338|339|340|341|342|343|344|345|346|347|348|349|350|351|352|353|354|355|356|357|358|359|360|361|362|363|364|365|366|367|368|369|370|371|372|373|374|375|376|377|378|379|380|381|382|383|384|385|386|387|388|389|390|391|392|393|394|395|396|397|398|399|400|401|402|403|404|405|406|407|408|409|410|411|412|413|414|415|416|417|418|419|420|421|422|423|424|425|426|427|428|429|430|431|432|433|434|435|436|437|438|439|440|441|442|443|444|445|446|447|448|449|450|451|452|453|454|455|456|457|458|459|460|461|462|463|464|465|466|467|468|469|470|471|472|473|474|475|476|477|478|479|480|481|482|483|484|485|486|487|488|489|490|491|492|493|494|495|496|497|498|499|500|Minutes: 124.86\n",
      "\n",
      "4 /10. Working with: // Paper limit = True ( 1 ) // Collaborations = False ( SDC ) // Generations = 500\n",
      "  |1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20|21|22|23|24|25|26|27|28|29|30|31|32|33|34|35|36|37|38|39|40|41|42|43|44|45|46|47|48|49|50|51|52|53|54|55|56|57|58|59|60|61|62|63|64|65|66|67|68|69|70|71|72|73|74|75|76|77|78|79|80|81|82|83|84|85|86|87|88|89|90|91|92|93|94|95|96|97|98|99|100|101|102|103|104|105|106|107|108|109|110|111|112|113|114|115|116|117|118|119|120|121|122|123|124|125|126|127|128|129|130|131|132|133|134|135|136|137|138|139|140|141|142|143|144|145|146|147|148|149|150|151|152|153|154|155|156|157|158|159|160|161|162|163|164|165|166|167|168|169|170|171|172|173|174|175|176|177|178|179|180|181|182|183|184|185|186|187|188|189|190|191|192|193|194|195|196|197|198|199|200|201|202|203|204|205|206|207|208|209|210|211|212|213|214|215|216|217|218|219|220|221|222|223|224|225|226|227|228|229|230|231|232|233|234|235|236|237|238|239|240|241|242|243|244|245|246|247|248|249|250|251|252|253|254|255|256|257|258|259|260|261|262|263|264|265|266|267|268|269|270|271|272|273|274|275|276|277|278|279|280|281|282|283|284|285|286|287|288|289|290|291|292|293|294|295|296|297|298|299|300|301|302|303|304|305|306|307|308|309|310|311|312|313|314|315|316|317|318|319|320|321|322|323|324|325|326|327|328|329|330|331|332|333|334|335|336|337|338|339|340|341|342|343|344|345|346|347|348|349|350|351|352|353|354|355|356|357|358|359|360|361|362|363|364|365|366|367|368|369|370|371|372|373|374|375|376|377|378|379|380|381|382|383|384|385|386|387|388|389|390|391|392|393|394|395|396|397|398|399|400|401|402|403|404|405|406|407|408|409|410|411|412|413|414|415|416|417|418|419|420|421|422|423|424|425|426|427|428|429|430|431|432|433|434|435|436|437|438|439|440|441|442|443|444|445|446|447|448|449|450|451|452|453|454|455|456|457|458|459|460|461|462|463|464|465|466|467|468|469|470|471|472|473|474|475|476|477|478|479|480|481|482|483|484|485|486|487|488|489|490|491|492|493|494|495|496|497|498|499|500|Minutes: 112.29\n",
      "\n",
      "5 /10. Working with: // Paper limit = True ( 1 ) // Collaborations = False ( SDC ) // Generations = 500\n",
      "  |1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20|21|22|23|24|25|26|27|28|29|30|31|32|33|34|35|36|37|38|39|40|41|42|43|44|45|46|47|48|49|50|51|52|53|54|55|56|57|58|59|60|61|62|63|64|65|66|67|68|69|70|71|72|73|74|75|76|77|78|79|80|81|82|83|84|85|86|87|88|89|90|91|92|93|94|95|96|97|98|99|100|101|102|103|104|105|106|107|108|109|110|111|112|113|114|115|116|117|118|119|120|121|122|123|124|125|126|127|128|129|130|131|132|133|134|135|136|137|138|139|140|141|142|143|144|145|146|147|148|149|150|151|152|153|154|155|156|157|158|159|160|161|162|163|164|165|166|167|168|169|170|171|172|173|174|175|176|177|178|179|180|181|182|183|184|185|186|187|188|189|190|191|192|193|194|195|196|197|198|199|200|201|202|203|204|205|206|207|208|209|210|211|212|213|214|215|216|217|218|219|220|221|222|223|224|225|226|227|228|229|230|231|232|233|234|235|236|237|238|239|240|241|242|243|244|245|246|247|248|249|250|251|252|253|254|255|256|257|258|259|260|261|262|263|264|265|266|267|268|269|270|271|272|273|274|275|276|277|278|279|280|281|282|283|284|285|286|287|288|289|290|291|292|293|294|295|296|297|298|299|300|301|302|303|304|305|306|307|308|309|310|311|312|313|314|315|316|317|318|319|320|321|322|323|324|325|326|327|328|329|330|331|332|333|334|335|336|337|338|339|340|341|342|343|344|345|346|347|348|349|350|351|352|353|354|355|356|357|358|359|360|361|362|363|364|365|366|367|368|369|370|371|372|373|374|375|376|377|378|379|380|381|382|383|384|385|386|387|388|389|390|391|392|393|394|395|396|397|398|399|400|401|402|403|404|405|406|407|408|409|410|411|412|413|414|415|416|417|418|419|420|421|422|423|424|425|426|427|428|429|430|431|432|433|434|435|436|437|438|439|440|441|442|443|444|445|446|447|448|449|450|451|452|453|454|455|456|457|458|459|460|461|462|463|464|465|466|467|468|469|470|471|472|473|474|475|476|477|478|479|480|481|482|483|484|485|486|487|488|489|490|491|492|493|494|495|496|497|498|499|500|Minutes: 125.86\n",
      "\n",
      "6 /10. Working with: // Paper limit = True ( 1 ) // Collaborations = False ( SDC ) // Generations = 500\n",
      "  |1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20|21|22|23|24|25|26|27|28|29|30|31|32|33|34|35|36|37|38|39|40|41|42|43|44|45|46|47|48|49|50|51|52|53|54|55|56|57|58|59|60|61|62|63|64|65|66|67|68|69|70|71|72|73|74|75|76|77|78|79|80|81|82|83|84|85|86|87|88|89|90|91|92|93|94|95|96|97|98|99|100|101|102|103|104|105|106|107|108|109|110|111|112|113|114|115|116|117|118|119|120|121|122|123|124|125|126|127|128|129|130|131|132|133|134|135|136|137|138|139|140|141|142|143|144|145|146|147|148|149|150|151|152|153|154|155|156|157|158|159|160|161|162|163|164|165|166|167|168|169|170|171|172|173|174|175|176|177|178|179|180|181|182|183|184|185|186|187|188|189|190|191|192|193|194|195|196|197|198|199|200|201|202|203|204|205|206|207|208|209|210|211|212|213|214|215|216|217|218|219|220|221|222|223|224|225|226|227|228|229|230|231|232|233|234|235|236|237|238|239|240|241|242|243|244|245|246|247|248|249|250|251|252|253|254|255|256|257|258|259|260|261|262|263|264|265|266|267|268|269|270|271|272|273|274|275|276|277|278|279|280|281|282|283|284|285|286|287|288|289|290|291|292|293|294|295|296|297|298|299|300|301|302|303|304|305|306|307|308|309|310|311|312|313|314|315|316|317|318|319|320|321|322|323|324|325|326|327|328|329|330|331|332|333|334|335|336|337|338|339|340|341|342|343|344|345|346|347|348|349|350|351|352|353|354|355|356|357|358|359|360|361|362|363|364|365|366|367|368|369|370|371|372|373|374|375|376|377|378|379|380|381|382|383|384|385|386|387|388|389|390|391|392|393|394|395|396|397|398|399|400|401|402|403|404|405|406|407|408|409|410|411|412|413|414|415|416|417|418|419|420|421|422|423|424|425|426|427|428|429|430|431|432|433|434|435|436|437|438|439|440|441|442|443|444|445|446|447|448|449|450|451|452|453|454|455|456|457|458|459|460|461|462|463|464|465|466|467|468|469|470|471|472|473|474|475|476|477|478|479|480|481|482|483|484|485|486|487|488|489|490|491|492|493|494|495|496|497|498|499|500|Minutes: 100.97\n",
      "\n",
      "7 /10. Working with: // Paper limit = True ( 1 ) // Collaborations = False ( SDC ) // Generations = 500\n",
      "  |1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20|21|22|23|24|25|26|27|28|29|30|31|32|33|34|35|36|37|38|39|40|41|42|43|44|45|46|47|48|49|50|51|52|53|54|55|56|57|58|59|60|61|62|63|64|65|66|67|68|69|70|71|72|73|74|75|76|77|78|79|80|81|82|83|84|85|86|87|88|89|90|91|92|93|94|95|96|97|98|99|100|101|102|103|104|105|106|107|108|109|110|111|112|113|114|115|116|117|118|119|120|121|122|123|124|125|126|127|128|129|130|131|132|133|134|135|136|137|138|139|140|141|142|143|144|145|146|147|148|149|150|151|152|153|154|155|156|157|158|159|160|161|162|163|164|165|166|167|168|169|170|171|172|173|174|175|176|177|178|179|180|181|182|183|184|185|186|187|188|189|190|191|192|193|194|195|196|197|198|199|200|201|202|203|204|205|206|207|208|209|210|211|212|213|214|215|216|217|218|219|220|221|222|223|224|225|226|227|228|229|230|231|232|233|234|235|236|237|238|239|240|241|242|243|244|245|246|247|248|249|250|251|252|253|254|255|256|257|258|259|260|261|262|263|264|265|266|267|268|269|270|271|272|273|274|275|276|277|278|279|280|281|282|283|284|285|286|287|288|289|290|291|292|293|294|295|296|297|298|299|300|301|302|303|304|305|306|307|308|309|310|311|312|313|314|315|316|317|318|319|320|321|322|323|324|325|326|327|328|329|330|331|332|333|334|335|336|337|338|339|340|341|342|343|344|345|346|347|348|349|350|351|352|353|354|355|356|357|358|359|360|361|362|363|364|365|366|367|368|369|370|371|372|373|374|375|376|377|378|379|380|381|382|383|384|385|386|387|388|389|390|391|392|393|394|395|396|397|398|399|400|401|402|403|404|405|406|407|408|409|410|411|412|413|414|415|416|417|418|419|420|421|422|423|424|425|426|427|428|429|430|431|432|433|434|435|436|437|438|439|440|441|442|443|444|445|446|447|448|449|450|451|452|453|454|455|456|457|458|459|460|461|462|463|464|465|466|467|468|469|470|471|472|473|474|475|476|477|478|479|480|481|482|483|484|485|486|487|488|489|490|491|492|493|494|495|496|497|498|499|500|Minutes: 101.58\n",
      "\n",
      "8 /10. Working with: // Paper limit = True ( 1 ) // Collaborations = False ( SDC ) // Generations = 500\n",
      "  |1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20|21|22|23|24|25|26|27|28|29|30|31|32|33|34|35|36|37|38|39|40|41|42|43|44|45|46|47|48|49|50|51|52|53|54|55|56|57|58|59|60|61|62|63|64|65|66|67|68|69|70|71|72|73|74|75|76|77|78|79|80|81|82|83|84|85|86|87|88|89|90|91|92|93|94|95|96|97|98|99|100|101|102|103|104|105|106|107|108|109|110|111|112|113|114|115|116|117|118|119|120|121|122|123|124|125|126|127|128|129|130|131|132|133|134|135|136|137|138|139|140|141|142|143|144|145|146|147|148|149|150|151|152|153|154|155|156|157|158|159|160|161|162|163|164|165|166|167|168|169|170|171|172|173|174|175|176|177|178|179|180|181|182|183|184|185|186|187|188|189|190|191|192|193|194|195|196|197|198|199|200|201|202|203|204|205|206|207|208|209|210|211|212|213|214|215|216|217|218|219|220|221|222|223|224|225|226|227|228|229|230|231|232|233|234|235|236|237|238|239|240|241|242|243|244|245|246|247|248|249|250|251|252|253|254|255|256|257|258|259|260|261|262|263|264|265|266|267|268|269|270|271|272|273|274|275|276|277|278|279|280|281|282|283|284|285|286|287|288|289|290|291|292|293|294|295|296|297|298|299|300|301|302|303|304|305|306|307|308|309|310|311|312|313|314|315|316|317|318|319|320|321|322|323|324|325|326|327|328|329|330|331|332|333|334|335|336|337|338|339|340|341|342|343|344|345|346|347|348|349|350|351|352|353|354|355|356|357|358|359|360|361|362|363|364|365|366|367|368|369|370|371|372|373|374|375|376|377|378|379|380|381|382|383|384|385|386|387|388|389|390|391|392|393|394|395|396|397|398|399|400|401|402|403|404|405|406|407|408|409|410|411|412|413|414|415|416|417|418|419|420|421|422|423|424|425|426|427|428|429|430|431|432|433|434|435|436|437|438|439|440|441|442|443|444|445|446|447|448|449|450|451|452|453|454|455|456|457|458|459|460|461|462|463|464|465|466|467|468|469|470|471|472|473|474|475|476|477|478|479|480|481|482|483|484|485|486|487|488|489|490|491|492|493|494|495|496|497|498|499|500|Minutes: 92.08\n",
      "\n",
      "9 /10. Working with: // Paper limit = True ( 1 ) // Collaborations = False ( SDC ) // Generations = 500\n",
      "  |1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20|21|22|23|24|25|26|27|28|29|30|31|32|33|34|35|36|37|38|39|40|41|42|43|44|45|46|47|48|49|50|51|52|53|54|55|56|57|58|59|60|61|62|63|64|65|66|67|68|69|70|71|72|73|74|75|76|77|78|79|80|81|82|83|84|85|86|87|88|89|90|91|92|93|94|95|96|97|98|99|100|101|102|103|104|105|106|107|108|109|110|111|112|113|114|115|116|117|118|119|120|121|122|123|124|125|126|127|128|129|130|131|132|133|134|135|136|137|138|139|140|141|142|143|144|145|146|147|148|149|150|151|152|153|154|155|156|157|158|159|160|161|162|163|164|165|166|167|168|169|170|171|172|173|174|175|176|177|178|179|180|181|182|183|184|185|186|187|188|189|190|191|192|193|194|195|196|197|198|199|200|201|202|203|204|205|206|207|208|209|210|211|212|213|214|215|216|217|218|219|220|221|222|223|224|225|226|227|228|229|230|231|232|233|234|235|236|237|238|239|240|241|242|243|244|245|246|247|248|249|250|251|252|253|254|255|256|257|258|259|260|261|262|263|264|265|266|267|268|269|270|271|272|273|274|275|276|277|278|279|280|281|282|283|284|285|286|287|288|289|290|291|292|293|294|295|296|297|298|299|300|301|302|303|304|305|306|307|308|309|310|311|312|313|314|315|316|317|318|319|320|321|322|323|324|325|326|327|328|329|330|331|332|333|334|335|336|337|338|339|340|341|342|343|344|345|346|347|348|349|350|351|352|353|354|355|356|357|358|359|360|361|362|363|364|365|366|367|368|369|370|371|372|373|374|375|376|377|378|379|380|381|382|383|384|385|386|387|388|389|390|391|392|393|394|395|396|397|398|399|400|401|402|403|404|405|406|407|408|409|410|411|412|413|414|415|416|417|418|419|420|421|422|423|424|425|426|427|428|429|430|431|432|433|434|435|436|437|438|439|440|441|442|443|444|445|446|447|448|449|450|451|452|453|454|455|456|457|458|459|460|461|462|463|464|465|466|467|468|469|470|471|472|473|474|475|476|477|478|479|480|481|482|483|484|485|486|487|488|489|490|491|492|493|494|495|496|497|498|499|500|Minutes: 83.16\n",
      "\n",
      "10 /10. Working with: // Paper limit = True ( 1 ) // Collaborations = False ( SDC ) // Generations = 500\n",
      "  |1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20|21|22|23|24|25|26|27|28|29|30|31|32|33|34|35|36|37|38|39|40|41|42|43|44|45|46|47|48|49|50|51|52|53|54|55|56|57|58|59|60|61|62|63|64|65|66|67|68|69|70|71|72|73|74|75|76|77|78|79|80|81|82|83|84|85|86|87|88|89|90|91|92|93|94|95|96|97|98|99|100|101|102|103|104|105|106|107|108|109|110|111|112|113|114|115|116|117|118|119|120|121|122|123|124|125|126|127|128|129|130|131|132|133|134|135|136|137|138|139|140|141|142|143|144|145|146|147|148|149|150|151|152|153|154|155|156|157|158|159|160|161|162|163|164|165|166|167|168|169|170|171|172|173|174|175|176|177|178|179|180|181|182|183|184|185|186|187|188|189|190|191|192|193|194|195|196|197|198|199|200|201|202|203|204|205|206|207|208|209|210|211|212|213|214|215|216|217|218|219|220|221|222|223|224|225|226|227|228|229|230|231|232|233|234|235|236|237|238|239|240|241|242|243|244|245|246|247|248|249|250|251|252|253|254|255|256|257|258|259|260|261|262|263|264|265|266|267|268|269|270|271|272|273|274|275|276|277|278|279|280|281|282|283|284|285|286|287|288|289|290|291|292|293|294|295|296|297|298|299|300|301|302|303|304|305|306|307|308|309|310|311|312|313|314|315|316|317|318|319|320|321|322|323|324|325|326|327|328|329|330|331|332|333|334|335|336|337|338|339|340|341|342|343|344|345|346|347|348|349|350|351|352|353|354|355|356|357|358|359|360|361|362|363|364|365|366|367|368|369|370|371|372|373|374|375|376|377|378|379|380|381|382|383|384|385|386|387|388|389|390|391|392|393|394|395|396|397|398|399|400|401|402|403|404|405|406|407|408|409|410|411|412|413|414|415|416|417|418|419|420|421|422|423|424|425|426|427|428|429|430|431|432|433|434|435|436|437|438|439|440|441|442|443|444|445|446|447|448|449|450|451|452|453|454|455|456|457|458|459|460|461|462|463|464|465|466|467|468|469|470|471|472|473|474|475|476|477|478|479|480|481|482|483|484|485|486|487|488|489|490|491|492|493|494|495|496|497|498|499|500|Minutes: 80.43\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python391jvsc74a57bd009252b4e88fa85a0493145ce2e96115e8729ccb750fcebda0a5a24f7f8e19bfc",
   "display_name": "Python 3.9.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "metadata": {
   "interpreter": {
    "hash": "09252b4e88fa85a0493145ce2e96115e8729ccb750fcebda0a5a24f7f8e19bfc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}